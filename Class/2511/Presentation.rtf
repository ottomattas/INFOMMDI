{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh17040\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Before anything, we felt it necessary to go over three key concepts that we rely on heavily when discussing this research.\
\
First, artificial neural networks\'85\
Second, dimensionality reduction\'85\
Third, explainability\'85\
\
Filippo has prepared a wonderful demo in mentimeter but as we might get tight on time, we\'92re going to share it later on during discussion, so please not click on the you see under \'93explainability\'94 so we can test your classification skills. \
((((Are you a black box? How did you decide on the number?)))))\
\
Now, as we have established common ground and understanding about this research, let\'92s just jump into the research.\
\
Alright, so we are assuming that you have read the paper and won\'92t get stuck in the details. Instead, we are making a summary of the research; we will share some additional context; and finally, we will open it up for a broader discussion.\
\
Summary\
Summary\
\
This research has taken off, spun new research and spread its figurative wings. Before we go to the topic points, let\'92s look at the picture on the right. \
You can see the machine learning pipeline on the top, referring to common frameworks and approaches. There are many steps within the pipeline and this research is said to fall somewhere in the middle, so the understanding part. Essentially - this research should help understand models. We could even extend this notion by adding that visualising via this method discussed in the research, we could also iteratively improve feature quality. But this is not a fledged out idea yet, so let\'92s go to the points on the left.\
\
This research has been cited 190 times according to GScholar with later researchers having made use of the evaluation methods in their research.\
Also, it is fairly easy to say that this research has contributed to making better models overall. Nothing bad about visualising your ANN if you understand what you are really doing, right?\
And, this research has made it possible to extend the same techniques on Recurring NN, so the iterative process comes into play. If you don\'92t know about recurring NN, we are not going to extend on it here - I\'92ll just say, there is a temporal or a dynamic factor to it, so there is a recurring element.\
\
So, the research seems interesting, and makes quite some progress with connecting both fields of AI and dataviz. What did you think of this, though\'85\
\
First, we took two comments from the class and hope maybe Alex can spark the discussion by giving a response.\
And secondly, we have some open discussion points.\
\
So, the first student comment:\
Filippo will take the second:\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
As we still have time, I would generalise.\
\
First of all, a topic close to my heart - ecological validity - and how valid is this research actually in the real world.\
Where do you think, explainable AI is going? And should we tie this kind of bridging research (e.g AI/dataviz) more to the real world? Basically, should we look for validity in addition, to the researcher saying that \'93yes, this visualisation makes this black box more explainable for me\'94. So\'85 where is explainable AI going in your mind?}